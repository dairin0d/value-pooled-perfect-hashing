{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off https://stevehanov.ca/blog/?id=119\n",
    "# but modified to allow same-value collisions\n",
    "\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Install the numba package if you want to speed up the\n",
    "# calculations (though the script will work without it too)\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = (lambda f: f)\n",
    "\n",
    "@njit\n",
    "def fnv_hash(data, offset_basis):\n",
    "    # https://en.wikipedia.org/wiki/Fowler–Noll–Vo_hash_function\n",
    "    result = (offset_basis or 0x01000193) & 0xffffffff\n",
    "    for data_byte in data:\n",
    "        result = ((result * 0x01000193) ^ data_byte) & 0xffffffff\n",
    "    return result\n",
    "\n",
    "def key_to_bytes(key):\n",
    "    if isinstance(key, bytes): return key\n",
    "    if isinstance(key, str): return key.encode(\"utf-8\")\n",
    "    raise ValueError(f\"Not a bytes or str key: {key}\")\n",
    "\n",
    "class PerfectHashMap:\n",
    "    def __init__(self, hash, G, V, palette):\n",
    "        self.hash = hash\n",
    "        self.G = G # buckets with seeds\n",
    "        self.V = V # cells with values\n",
    "        self.palette = palette\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        key = key_to_bytes(key)\n",
    "        g = self.G[self.hash(key, 0) % len(self.G)]\n",
    "        p = self.V[self.hash(key, g) % len(self.V)]\n",
    "        return self.palette[p]\n",
    "    \n",
    "    def estimate_min_size(self):\n",
    "        min_bits = (lambda n: math.ceil(math.log(n, 2)))\n",
    "        unique_g = set(self.G) # unique seeds\n",
    "        g_count = len(self.G) # number of buckets\n",
    "        v_count = len(self.V) # number of value cells\n",
    "        p_count = len(self.palette) # value palette size\n",
    "        u_count = len(unique_g) # number of unique seeds\n",
    "        u_max = max(unique_g) # max value of seeds\n",
    "        # Buckets, case A: store seeds in palette, buckets store palette indices\n",
    "        g_bits_a = g_count * min_bits(u_count) + u_count * min_bits(u_max+1)\n",
    "        # Buckets, case B: store seeds in buckets directly\n",
    "        g_bits_b = g_count * min_bits(u_max+1)\n",
    "        # Size of buckets is assumed to be the best of the cases A & B\n",
    "        g_bits = min(g_bits_a, g_bits_b)\n",
    "        # Value cells: store palette indices in the value cells\n",
    "        v_bits = v_count * min_bits(p_count)\n",
    "        # Finally, add buckets size and value cells size to obtain the estimate\n",
    "        # (the cost of storing the counts themselves is assumed to be constant)\n",
    "        return g_bits + v_bits\n",
    "\n",
    "# Tries to create a value-pooled perfect hash map using the given python dictionary.\n",
    "# If some keys map to identical values, they can potentially be \"pooled\" together.\n",
    "def value_pooled_perfect_hash(mapping, hash, size_G=None, size_V=None, attempts=1000):\n",
    "    # Build a palette of unique values\n",
    "    palette = list(set(mapping.values()))\n",
    "    palette_map = {v: i for i, v in enumerate(palette)}\n",
    "    \n",
    "    size_G = max(size_G or 0, 1)\n",
    "    size_V = max(size_V or size_G, len(palette))\n",
    "    \n",
    "    G = np.zeros(size_G, dtype=int)\n",
    "    V = np.zeros(size_V, dtype=int)\n",
    "    T = np.zeros(size_V, dtype=int)\n",
    "    \n",
    "    # Step 1: Place all of the keys into buckets\n",
    "    buckets = [{} for i in range(size_G)]\n",
    "    \n",
    "    for key, value in mapping.items():\n",
    "        key = key_to_bytes(key)\n",
    "        value = palette_map[value] + 1\n",
    "        \n",
    "        bucket = buckets[hash(key, 0) % size_G]\n",
    "        keys = bucket.get(value)\n",
    "        if keys is None:\n",
    "            keys = []\n",
    "            bucket[value] = keys\n",
    "        keys.append(key)\n",
    "    \n",
    "    for i in range(size_G):\n",
    "        buckets[i] = list(buckets[i].items())\n",
    "    \n",
    "    # Step 2: Sort the buckets and process the ones with the most items first.\n",
    "    buckets.sort(key=len, reverse=True)\n",
    "    \n",
    "    for bucket in buckets:\n",
    "        if len(bucket) <= 0: break\n",
    "        \n",
    "        rehashes = 0\n",
    "        g = 1\n",
    "        item = 0\n",
    "        T[:] = V[:]\n",
    "        \n",
    "        # Repeatedly try different seeds until we find a hash function\n",
    "        # that places all items in the bucket into free/matching slots\n",
    "        while item < len(bucket):\n",
    "            value, keys = bucket[item]\n",
    "            \n",
    "            success = True\n",
    "            for key in keys:\n",
    "                slot = hash(key, g) % size_V\n",
    "                if not T[slot]:\n",
    "                    T[slot] = value\n",
    "                elif T[slot] != value:\n",
    "                    success = False\n",
    "                    break\n",
    "            \n",
    "            if success:\n",
    "                item += 1\n",
    "            else:\n",
    "                rehashes += 1\n",
    "                if rehashes > attempts: return None\n",
    "                \n",
    "                g += 1\n",
    "                item = 0\n",
    "                T[:] = V[:]\n",
    "        \n",
    "        value, keys = bucket[0]\n",
    "        G[hash(keys[0], 0) % size_G] = g\n",
    "        \n",
    "        V[:] = T[:]\n",
    "    \n",
    "    V -= 1\n",
    "    \n",
    "    return PerfectHashMap(hash, G, V, palette)\n",
    "\n",
    "def generate_random_string(length):\n",
    "    chars = string.ascii_letters + string.digits + string.punctuation\n",
    "    return ''.join(random.choice(chars) for _ in range(length))\n",
    "\n",
    "def generate_mapping(key_count, value_count, binarize_values=False):\n",
    "    if value_count <= 2:\n",
    "        binarize_values = False\n",
    "    \n",
    "    if binarize_values:\n",
    "        values = [0, 1]\n",
    "    else:\n",
    "        values = list(i+1 for i in range(value_count))\n",
    "    \n",
    "    keys = set()\n",
    "    while len(keys) < key_count:\n",
    "        keys.add(generate_random_string(10))\n",
    "    \n",
    "    if binarize_values:\n",
    "        value_bits = math.ceil(math.log(value_count, 2))\n",
    "        keys = {(chr(b)+k) for k in keys for b in range(value_bits)}\n",
    "    \n",
    "    keys = list(keys)\n",
    "    random.shuffle(keys)\n",
    "    \n",
    "    mapping = {k: values[i % len(values)] for i, k in enumerate(keys)}\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def scan_parameters(mapping, attempts):\n",
    "    key_count = len(mapping)\n",
    "    value_count = len(set(mapping.values()))\n",
    "    \n",
    "    size_G_min = 1\n",
    "    size_G_max = key_count\n",
    "    size_V_min = value_count\n",
    "    size_V_max = key_count\n",
    "    \n",
    "    img = np.zeros((size_G_max, size_V_max, 3))\n",
    "    color_exists = (0.0, 0.0, 0.8)\n",
    "    color_best = (0.0, key_count*0.25, 0.0)\n",
    "    \n",
    "    smallest = None\n",
    "    for size_G in range(1, size_G_max+1):\n",
    "        line = []\n",
    "        for size_V in range(1, size_V_max+1):\n",
    "            if (size_G >= size_G_min) and (size_V >= size_V_min):\n",
    "                result = value_pooled_perfect_hash(mapping, fnv_hash, size_G, size_V, attempts=attempts)\n",
    "                if result:\n",
    "                    min_size = result.estimate_min_size()\n",
    "                    if (smallest is None) or (min_size < smallest[0]):\n",
    "                        smallest = (min_size, size_V, size_G)\n",
    "                    img[size_G-1, size_V-1] = color_exists\n",
    "                    continue\n",
    "    \n",
    "    min_size, size_V, size_G = smallest\n",
    "    img[size_G-1, size_V-1] = color_best\n",
    "    \n",
    "    return img, smallest\n",
    "\n",
    "# Note: the parameters found this way are likely suboptimal,\n",
    "# and an exhaustive search along the boundary region would\n",
    "# yield a (typically ~2x) smaller size\n",
    "def find_parameters(mapping, attempts):\n",
    "    key_count = len(mapping)\n",
    "    value_count = len(set(mapping.values()))\n",
    "    \n",
    "    size_min = value_count\n",
    "    size_max = key_count\n",
    "    size = (size_min + size_max) // 2\n",
    "    \n",
    "    best_result = None\n",
    "    \n",
    "    while size_min < size_max:\n",
    "        result = value_pooled_perfect_hash(mapping, fnv_hash, size, attempts=attempts)\n",
    "        \n",
    "        if result is None:\n",
    "            size_min = size+1\n",
    "        else:\n",
    "            size_max = size-1\n",
    "            if (best_result is None) or (len(result.G) < len(best_result.G)):\n",
    "                best_result = result\n",
    "        \n",
    "        size = (size_min + size_max) // 2\n",
    "    \n",
    "    return best_result\n",
    "\n",
    "print()\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "experiments_count = 10\n",
    "key_count = 32\n",
    "value_count = 2\n",
    "binarize_values = True\n",
    "attempts = 1000\n",
    "\n",
    "calculate_full_grid = True\n",
    "\n",
    "if calculate_full_grid:\n",
    "    min_sizes = []\n",
    "    \n",
    "    effective_key_count = key_count\n",
    "    if binarize_values:\n",
    "        value_bits = math.ceil(math.log(value_count, 2))\n",
    "        effective_key_count = key_count * value_bits\n",
    "    \n",
    "    img_accum = np.zeros((effective_key_count, effective_key_count, 3))\n",
    "    accum_count = 0\n",
    "    \n",
    "    for i in range(experiments_count):\n",
    "        mapping = generate_mapping(key_count, value_count, binarize_values)\n",
    "        img, smallest = scan_parameters(mapping, attempts)\n",
    "        min_sizes.append(smallest[0])\n",
    "        img_accum += img\n",
    "        accum_count += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(np.clip(img_accum/accum_count, 0, 1))\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('len(V)')\n",
    "        ax.set_ylabel('len(G)')\n",
    "        plt.show()\n",
    "        time.sleep(0.1)  # Pause to make the updates visible\n",
    "    \n",
    "    print(f\"Min sizes: {min_sizes}\")\n",
    "else:\n",
    "    mapping = generate_mapping(key_count, value_count, binarize_values)\n",
    "    result = find_parameters(mapping, attempts)\n",
    "    \n",
    "    print(f\"Keys: {key_count}, values: {value_count}\")\n",
    "    print(f\"Smallest found size: {result.estimate_min_size()} bits\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
